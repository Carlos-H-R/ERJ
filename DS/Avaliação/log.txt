Para teste inicial da base de dados foram selecionados:
    - os primeiros 952 registros para treino (equivalente a 85% da base)
    - os ultimos 168 registros para teste (equivalente a 15% da base)

Primeira tentativa de gerar o modelo resultou em erro devido a conversão de espaços vazios em float
    -> Para próxima tentativa popular os missing values com valor padrão para observar o comportamento inicial do modelo

# Todos os missing values foram preenchidos com valor 0
Resultados:
    Accuracy    -> 0.726
    Precision   -> 0.954
    Recall      -> 0.726
    F1          -> 0.726


Identificando Outliers
    -> Para identificar outliers analisar a natureza do atributo e observar o comportamento dos registros
    -> Usada a distribuição padrão
    -> Considerando 2a

    -> Para os atributos binários é removido qualquer coisa que não seja 0 ou 1

Resultados (substituindo missing por 1):
    Accuracy    -> 0.7857142857142857
    Precision   -> 0.9104477611940298
    Recall      -> 0.7857142857142857
    F1          -> 0.7857142857142857

Resultados (substituindo missing por 0):
    Accuracy    -> 0.7142857142857143
    Precision   -> 0.9152542372881356
    Recall      -> 0.7142857142857143
    F1          -> 0.7142857142857143



Tratando Missing Values
    - KNN (Usado KNN para Todos):
    - Probabilidade

Resultados (usando KNN para todos):
    Acuracia: 0.7976190476190477
    Precisao: 0.9117647058823529
    Recall:   0.8493150684931506
    Conf. M:  [[ 10  12]
            [ 22 124]]

Resultados (usando KNN nos 3 primeiros atributos e Probabilidade no restante):



Nomalização e discretização
    - Os 3 primeiros atributos são inteiros não negativos e estão na mesma escala
    - Testar normalizar os tres primeiros atributos
        
Resultados:        
        Acuracia: 0.7142857142857143
        Precisao: 0.9375
        Recall:   0.7191780821917808
        Conf. M:  [[ 15   7]
        [ 41 105]]
    Como se pode observar houve uma piora ao normalizar os primeiros atributos
    Provavelmente isso deve ocorrer pois as entradas de teste não estão normalizadas

-> Normalização removida


Seleção de variável
    - olhar para a árvore e observar os atributos mais relevantes

    
    - usar combinações exaustivas de atributos para escolher quais remover


Testar os resultados dessa base com outro modelo (tava pensando no Naive Bayes)




- Próximas tarefas: 
    1. Identificar Outliers
    2. Definir Como completar missing value de forma mais adequada
    3. Verificar se é necessário normalizar ou discretizar
    4. Seleção de variáveis/redução da base

    Obs.: A cada tarefa deve-se reportar o quê foi feito e o porquê.
          Rodar o modelo e usar os resultados como parâmetro para as decisões
          A meta é elevar as métricas até pelo menos 0.9


Script para calcular a frequência de preenchimento dos atributos
    frequencia = base.count()
    frequencia = frequencia.map(lambda x: x / 1120)
    print(frequencia)



Algumas questões:
    As alterações só devem ser feitas na base de treino, então como fazer a base de teste rodar no modelo?
    