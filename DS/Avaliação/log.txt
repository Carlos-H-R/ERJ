Para teste inicial da base de dados foram selecionados:
    - os primeiros 952 registros para treino (equivalente a 85% da base)
    - os ultimos 168 registros para teste (equivalente a 15% da base)

Primeira tentativa de gerar o modelo resultou em erro devido a conversão de espaços vazios em float
    -> Para próxima tentativa popular os missing values com valor padrão para observar o comportamento inicial do modelo

# Todos os missing values foram preenchidos com valor 0
Resultados:
    Accuracy    -> 0.726
    Precision   -> 0.954
    Recall      -> 0.726
    F1          -> 0.726


Identificando Outliers
    -> Para identificar outliers analisar a natureza do atributo e observar o comportamento dos registros
    -> Usada a distribuição padrão
    -> Considerando 2a

    -> Para os atributos binários é removido qualquer coisa que não seja 0 ou 1

Resultados (substituindo missing por 1):
    Accuracy    -> 0.7857142857142857
    Precision   -> 0.9104477611940298
    Recall      -> 0.7857142857142857
    F1          -> 0.7857142857142857

Resultados (substituindo missing por 0):
    Accuracy    -> 0.7142857142857143
    Precision   -> 0.9152542372881356
    Recall      -> 0.7142857142857143
    F1          -> 0.7142857142857143



Tratando Missing Values
    - KNN (Usado KNN para Todos):
    - Probabilidade

Resultados (usando KNN para todos 10-neighbors):
    Acuracia: 0.7976190476190477
    Precisao: 0.9117647058823529
    Recall:   0.8493150684931506
    Conf. M:  [[ 10  12]
            [ 22 124]]

Resultados (usando KNN para todos 1-neighbor):
    Acuracia: 0.8333333333333334
    Precisao: 0.927536231884058
    Recall:   0.8767123287671232
    Conf. M:  [[ 12  10]
               [ 18 128]]



Nomalização e discretização
    - Os 3 primeiros atributos são inteiros não negativos e estão na mesma escala
    - Testar normalizar os tres primeiros atributos
        
Resultados:        
        Acuracia: 0.7142857142857143
        Precisao: 0.9375
        Recall:   0.7191780821917808
        Conf. M:  [[ 15   7]
        [ 41 105]]
    Como se pode observar houve uma piora ao normalizar os primeiros atributos
    Provavelmente isso deve ocorrer pois as entradas de teste não estão normalizadas

-> Normalização removida


Alterando a maneira que vai ser dividido a base de treino e a de teste:
    - A base é muito desbalanceada em relação a classe de saída (Evolução)
    - Isso está impossibilitando o uso do algoritmo ReliefF
    - Por isso se faz necessário mudar a maneira como é dividida a base 
        para gerantir que as frações não fiquem desbalanceadas

    -> Em vez de dividir diretamente com índices, passaremos a utilizar o 
        train_test_split(com stratify) para dividir garantindo balanceamento

    Resultado com (train_test_split(data, target, test_size=0.2, random_state=42, stratify=target)):
        Acuracia: 0.6696428571428571
        Precisao: 0.8633540372670807
        Recall:   0.7277486910994765
        Conf. M:  [[ 11  22]
                   [ 52 139]]

    Resultado com (train_test_split(data, target, test_size=0.3, random_state=40, stratify=target)):
        Acuracia: 0.7708333333333334
        Precisao: 0.9233870967741935
        Recall:   0.7979094076655052
        Conf. M:  [[ 30  19]
                   [ 58 229]]

    Resultado com (train_test_split(data, target, test_size=0.3, random_state=40)):
        Acuracia: 0.7529761904761905
        Precisao: 0.9117647058823529
        Recall:   0.7777777777777778
        Conf. M:  [[ 36  21]
                   [ 62 217]]

    Resultado com (data, target, test_size=0.15, random_state=40):
        Acuracia: 0.7380952380952381
        Precisao: 0.9292035398230089
        Recall:   0.7446808510638298
        Conf. M:  [[ 19   8]
                   [ 36 105]]

    Resultado com (data, target, test_size=0.15, random_state=40, stratify=target):
        Acuracia: 0.7738095238095238
        Precisao: 0.92
        Recall:   0.8041958041958042
        Conf. M:  [[ 15  10]
                   [ 28 115]]

    Resultado com (data, target, test_size=0.15, random_state=46, stratify=target):
        Acuracia: 0.8035714285714286
        Precisao: 0.9296875
        Recall:   0.8321678321678322
        Conf. M:  [[ 16   9]
                   [ 24 119]]

    -> É possível observar que a maneira como os dados são distribuidos afetam bastante o resultado 
    

Seleção de variável
    - usado ReliefF (n_features_to_select=12, n_neighbors=30)

Resultado (Com o RelliefF escolhendo apenas 6 atributos):
    Acuracia: 0.8333333333333334
    Precisao: 0.927536231884058
    Recall:   0.8767123287671232
    Conf. M:  [[ 12  10]
               [ 18 128]]

Resultado (Com o RelliefF escolhendo apenas 7 atributos):
    Acuracia: 0.8214285714285714
    Precisao: 0.9202898550724637
    Recall:   0.8698630136986302
    Conf. M:  [[ 11  11]
               [ 19 127]]


-> Como se trata de uma base pequena e desbalanceada, ajustar o modelo para melhorar as métricas tráz um grande risco de gerar um overfitting


Testar os resultados dessa base com outro modelo (tava pensando no Naive Bayes)
