Para teste inicial da base de dados foram selecionados:
    - os primeiros 952 registros para treino (equivalente a 85% da base)
    - os ultimos 168 registros para teste (equivalente a 15% da base)

Primeira tentativa de gerar o modelo resultou em erro devido a conversão de espaços vazios em float
    -> Para próxima tentativa popular os missing values com valor padrão para observar o comportamento inicial do modelo

# Todos os missing values foram preenchidos com valor 0
Resultados:
    Accuracy    -> 0.726
    Precision   -> 0.954
    Recall      -> 0.726
    F1          -> 0.726


Identificando Outliers
    -> Para identificar outliers analisar a natureza do atributo e observar o comportamento dos registros
    -> Usada a distribuição padrão
    -> Considerando 2a

    -> Para os atributos binários é removido qualquer coisa que não seja 0 ou 1

Resultados (substituindo missing por 1):
    Accuracy    -> 0.7857142857142857
    Precision   -> 0.9104477611940298
    Recall      -> 0.7857142857142857
    F1          -> 0.7857142857142857

Resultados (substituindo missing por 0):
    Accuracy    -> 0.7142857142857143
    Precision   -> 0.9152542372881356
    Recall      -> 0.7142857142857143
    F1          -> 0.7142857142857143



Tratando Missing Values
    - KNN (Usado KNN para Todos):
    - Probabilidade

Resultados (usando KNN para todos):
    Acuracia: 0.7976190476190477
    Precisao: 0.9117647058823529
    Recall:   0.8493150684931506
    Conf. M:  [[ 10  12]
            [ 22 124]]

Resultados (usando KNN nos 3 primeiros atributos e Probabilidade no restante):



Nomalização e discretização
    - Os 3 primeiros atributos são inteiros não negativos e estão na mesma escala
    - Testar normalizar os tres primeiros atributos
        
Resultados:        
        Acuracia: 0.7142857142857143
        Precisao: 0.9375
        Recall:   0.7191780821917808
        Conf. M:  [[ 15   7]
        [ 41 105]]
    Como se pode observar houve uma piora ao normalizar os primeiros atributos
    Provavelmente isso deve ocorrer pois as entradas de teste não estão normalizadas

-> Normalização removida


Alterando a maneira que vai ser dividido a base de treino e a de teste:
    - A base é muito desbalanceada em relação a classe de saída (Evolução)
    - Isso está impossibilitando o uso do algoritmo ReliefF
    - Por isso se faz necessário mudar a maneira como é dividida a base 
        para gerantir que as frações não fiquem desbalanceadas

    -> Em vez de dividir diretamente com índices, passaremos a utilizar o 
        StratifiedKFold para dividir garantindo balanceamento


Seleção de variável
    - olhar para a árvore e observar os atributos mais relevantes

    
    - usar combinações exaustivas de atributos para escolher quais remover

Resultado (Com o RelliefF escolhendo apenas 6 atributos):
    Acuracia: 0.8333333333333334
    Precisao: 0.927536231884058
    Recall:   0.8767123287671232
    Conf. M:  [[ 12  10]
               [ 18 128]]

Resultado (Com o RelliefF escolhendo apenas 7 atributos):
    Acuracia: 0.8214285714285714
    Precisao: 0.9202898550724637
    Recall:   0.8698630136986302
    Conf. M:  [[ 11  11]
               [ 19 127]]


balanceamento
A base é desbalanceada e portando pode ter resultado inadequados
- 


Testar os resultados dessa base com outro modelo (tava pensando no Naive Bayes)




- Próximas tarefas: 
    1. Identificar Outliers
    2. Definir Como completar missing value de forma mais adequada
    3. Verificar se é necessário normalizar ou discretizar
    4. Seleção de variáveis/redução da base

    Obs.: A cada tarefa deve-se reportar o quê foi feito e o porquê.
          Rodar o modelo e usar os resultados como parâmetro para as decisões
          A meta é elevar as métricas até pelo menos 0.9


Script para calcular a frequência de preenchimento dos atributos
    frequencia = base.count()
    frequencia = frequencia.map(lambda x: x / 1120)
    print(frequencia)



Algumas questões:
    As alterações só devem ser feitas na base de treino, então como fazer a base de teste rodar no modelo?
    